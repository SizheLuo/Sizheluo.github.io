---
layout: post
title: "进程管理"
date: 2023-09-07
description: "进程管理"
tag: 操作系统
---

### 前言

　　`前言`内容。

### 目录

* [第一章](#chapter1)
* [第二章](#chapter2)
* [第三章](#chapter3)
* [第四章](#chapter4)
* [第五章](#chapter5)
* [第六章](#chapter6)
* [第七章](#chapter7)
* [第八章](#chapter8)

### <a name="chapter1"></a>进程

1. 并行、并发
2. 进程的状态：运行状态、就绪状态、阻塞状态、创建状态、结束状态、阻塞挂起状态、就绪挂起状态
3. 进程控制块PCB：链表->相同的状态、task_struct->mm_struct->vm_area_struct
4. 上下文切换： 

		(1) CPU上下文切换：CPU寄存器和程序计数器
		(2) 进程上下文切换：虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源；发生场景：时间片调度、系统资源不足暂时挂起、sleep、高优先级抢占、中断
5. 进程通信：由于每个进程的用户空间都是独立的，不能相互访问，这时就需要借助内核空间来实现进程间通信，原因很简单，每个进程都是共享一个内核空间。

		(1) 管道：int pipe(int fd[2])、匿名管道（只能在父子进程通信）、命名管道（p设备文件、先进先出）
		(2) 消息队列：send、receive、涉及用户态与内核态之间的消息拷贝
		(3) 共享内存（多进程竞争问题）
		(4) 信号量：两个原子操作-P操作&V操作
		(5) 信号：异常情况下的工作模型，需要用信号的方式通知进程，用`kill -l`命令，查看所有的信号

![](https://s3.uuu.ovh/imgs/2023/09/09/1d075237841da82a.png)

		(6) Socket：跨网络进程通信，int socket(int domain, int type, int protocal)

![](https://s3.uuu.ovh/imgs/2023/09/09/5f387c37bb63e59b.png)

- 服务端和客户端初始化`socket`，得到文件描述符；
- 服务端调用`bind`，将绑定在IP地址和端口;
- 服务端调用`listen`，进行监听；
- 服务端调用`accept`，等待客户端连接；
- 客户端调用`connect`，向服务器端的地址和端口发起连接请求；
- 服务端`accept`返回用于传输的`socket`的文件描述符；
- 客户端调用`write`写入数据；服务端调用`read`读取数据；
- 客户端断开连接时，会调用`close`，那么服务端`read`读取数据的时候，就会读取到了`EOF`，待处理完数据后，服务端调用`close`，表示连接关闭。

这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。

QA:
----------
> 一个进程最多可以创建多少个线程？

这个问题跟两个东西有关系：

- `进程的虚拟内存空间上限`，因为创建一个线程，操作系统需要为其分配一个栈空间（8MB），如果线程数量越多，所需的栈空间就要越大，那么虚拟内存就会占用的越多。
- `系统参数限制`，虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数。

32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。

> 线程崩溃了，进程也会崩溃吗？

 C/C++ 语言里，线程崩溃后，进程也会崩溃，而 Java 语言里却不会。

### <a name="chapter2"></a>线程

1. 线程间共享代码段、数据段、打开的文件等资源，但各自有一套独立的寄存器和栈
2. 线程上下文切换：

		(1) 不同进程的线程，则与进程上下文切换基本一致
		(2) 同属于一个进程，虚拟内存等资源保持不变，只需切换私有数据、寄存器和栈等不共享数据
3. 线程的实现：用户线程、内核线程、轻量级进程
4. 线程控制块TCB

### <a name="chapter3"></a>进程与线程的比较

1. 进程是资源（包括内存、打开的文件等）分配的基本单位，线程是CPU调度的基本单位
2. 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈
3. 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系
4. 线程能减少开销：

        (1) 创建快、释放快
		(2) 切换快，不需要切换页表等
		(3) 共享进程内存和文件资源，通信开销小

### <a name="chapter4"></a>调度

1. 调度时机：
		
		(1) 非抢占式调度算法：让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程
		(2) 抢占式调度算法：让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。需要在时间间隔的末端发生时钟中断，也就是常说的时间片机制
2. 调度算法

		(1) 先来先服务(First Come First Serve, FCFS)
		(2) 最短作业优先(Shortest Job First, SJF)
		(3) 高响应比优先(Highest Response Ratio Next, HRRN)
		(4) 时间片轮转(Round Robin, RR)
		(5) 最高优先级(Highest Priority First, HPF)
		(6) 多级反馈队列(Multilevel Feedback Queue,MFQ)

### <a name="chapter5"></a>锁类别

**互斥锁与自旋锁**
----------
- <font color=Blue>互斥锁</font>加锁失败后，线程会<font color=Blue>释放CPU</font>，给其他线程
- <font color=Blue>自旋锁</font>加锁失败后，线程会<font color=Blue>忙等</font>，直到拿到锁
- 当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对

对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，会有两次线程上下文切换的成本。

> 被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。

自旋锁是通过 CPU 提供的`CAS`函数（*Compare And Swap*, 硬件级原子指令），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁
来说，会快一些，开销也小一些。

> 在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。

**读写锁**
----------
- 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据
- 一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞

读写锁可以分为「读优先锁」和「写优先锁」

- 读优先锁:当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%94%81/%E8%AF%BB%E4%BC%98%E5%85%88%E9%94%81%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

- 写优先锁:当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取写锁

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%94%81/%E5%86%99%E4%BC%98%E5%85%88%E9%94%81%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

- 公平策略:用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/34-%E8%AF%BB%E8%80%85%E5%86%99%E8%80%85-%E6%96%B9%E6%A1%88%E4%B8%89%E7%A4%BA%E4%BE%8B.jpg)

**乐观锁与悲观锁**
----------
- 互斥锁、自旋锁、读写锁，都是属于悲观锁。
- 乐观锁：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。

> 只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁，例如`在线文档`、`Git`、`SVN`。

QA:
----------
> CAS 不是乐观锁吗，为什么基于 CAS 实现的自旋锁是悲观锁？

CAS 是乐观锁没错，但是 CAS 和自旋锁不同之处，自旋锁基于 CAS 加了while 或者睡眠 CPU 的操作而产生自旋的效果，加锁失败会忙等待直到拿到锁，自旋锁是要需要事先拿到锁才能修改数据的，所以算悲观锁。

### <a name="chapter6"></a>死锁

死锁只有同时满足以下四个条件才会发生：

- 互斥条件：多个线程不能同时使用同一个资源
- 持有并等待条件：线程A在等待资源2的同时并不会释放自己已经持有的资源1
- 不可剥夺条件：在自己使用完之前不能被其他线程获取
- 环路等待条件：两个线程获取资源的顺序构成了环形链

		//线程函数 A
		void *threadA_proc(void *data)
		{
		    printf("thread A waiting get ResourceA \n");
		    pthread_mutex_lock(&mutex_A);
		    printf("thread A got ResourceA \n");
		    
		    sleep(1);
		    
		    printf("thread A waiting get ResourceB \n");
		    pthread_mutex_lock(&mutex_B);
		    printf("thread A got ResourceB \n");
		
		    pthread_mutex_unlock(&mutex_B);
		    pthread_mutex_unlock(&mutex_A);
		    return (void *)0;
		}

		//线程函数 B
		void *threadB_proc(void *data)
		{
		    printf("thread B waiting get ResourceB \n");
		    pthread_mutex_lock(&mutex_B);
		    printf("thread B got ResourceB \n");
		    
		    sleep(1);
		    
		    printf("thread B waiting  get ResourceA \n");
		    pthread_mutex_lock(&mutex_A);
		    printf("thread B got ResourceA \n");
		    
		    pthread_mutex_unlock(&mutex_A);
		    pthread_mutex_unlock(&mutex_B);
		    return (void *)0;
		}

		thread B waiting get ResourceB 
		thread B got ResourceB 
		thread A waiting get ResourceA 
		thread A got ResourceA 
		thread B waiting get ResourceA 
		thread A waiting get ResourceB 
		// 阻塞中...
		// 可用gdb进行排查

----------

避免死锁：
- 资源有序分配：线程 A 和 线程 B 获取资源的顺序要一样，打破环路等待条件。

		//线程 B 函数，同线程 A 一样，先获取互斥锁 A，然后获取互斥锁 B
		void *threadB_proc(void *data)
		{
		    printf("thread B waiting get ResourceA \n");
		    pthread_mutex_lock(&mutex_A);
		    printf("thread B got ResourceA \n");
		    
		    sleep(1);
		    
		    printf("thread B waiting  get ResourceB \n");
		    pthread_mutex_lock(&mutex_B);
		    printf("thread B got ResourceB \n");
		    
		    pthread_mutex_unlock(&mutex_B);
		    pthread_mutex_unlock(&mutex_A);
		    return (void *)0;
		}

### <a name="chapter7"></a>锁的种类

    第七章内容

### <a name="chapter8"></a>第八章

    第八章内容

### 参考资源

    参考资源

转载请注明：[sizheluo的博客](https://sizheluo.github.io) » [文章标题](文章链接)